package com.yuwei.yunduanban

import android.content.Context
import android.graphics.Bitmap
import android.graphics.PixelFormat
import android.hardware.display.DisplayManager
import android.hardware.display.VirtualDisplay
import android.media.Image
import android.media.ImageReader
import android.media.projection.MediaProjection
import android.os.Handler
import android.os.Looper
import android.util.DisplayMetrics
import android.util.Log
import android.view.WindowManager
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.chinese.ChineseTextRecognizerOptions
import com.huawei.hms.mlsdk.MLAnalyzerFactory
import com.huawei.hms.mlsdk.common.MLFrame
import com.huawei.hms.mlsdk.text.MLLocalTextSetting
import com.huawei.hms.mlsdk.text.MLTextAnalyzer
import kotlinx.coroutines.suspendCancellableCoroutine
import kotlin.coroutines.resume
import kotlin.coroutines.resumeWithException

/**
 * OCRæˆªå±å’Œæ–‡å­—è¯†åˆ«ç®¡ç†å™¨
 * æ”¯æŒåä¸ºML Kitå’ŒGoogle ML KitåŒå¼•æ“
 */
class OCRManager(private val context: Context) {
    
    private var mediaProjection: MediaProjection? = null
    private var imageReader: ImageReader? = null
    private var virtualDisplay: VirtualDisplay? = null
    
    // Google ML Kitè¯†åˆ«å™¨
    private val googleTextRecognizer = TextRecognition.getClient(ChineseTextRecognizerOptions.Builder().build())
    
    // åä¸ºML Kitè¯†åˆ«å™¨
    private var huaweiTextAnalyzer: MLTextAnalyzer? = null
    
    // OCRå¼•æ“ç±»å‹
    private var ocrEngine: OCREngine = OCREngine.UNKNOWN
    
    private val displayMetrics = DisplayMetrics()
    private val windowManager = context.getSystemService(Context.WINDOW_SERVICE) as WindowManager
    
    companion object {
        private const val TAG = "OCRManager"
        private const val VIRTUAL_DISPLAY_NAME = "YunDuanBan-ScreenCapture"
    }
    
    enum class OCREngine {
        HUAWEI_ML_KIT,  // åä¸ºML Kitï¼ˆåä¸ºè®¾å¤‡ä¼˜å…ˆï¼‰
        GOOGLE_ML_KIT,  // Google ML Kitï¼ˆé€šç”¨æ–¹æ¡ˆï¼‰
        UNKNOWN         // æœªåˆå§‹åŒ–
    }
    
    init {
        windowManager.defaultDisplay.getMetrics(displayMetrics)
        initOCREngine()
    }
    
    /**
     * åˆå§‹åŒ–OCRå¼•æ“ï¼Œä¼˜å…ˆä½¿ç”¨åä¸ºML Kit
     */
    private fun initOCREngine() {
        try {
            // å°è¯•åˆå§‹åŒ–åä¸ºML Kit
            val setting = MLLocalTextSetting.Factory()
                .setOCRMode(MLLocalTextSetting.OCR_DETECT_MODE)
                .setLanguage("zh")
                .create()
            huaweiTextAnalyzer = MLAnalyzerFactory.getInstance().getLocalTextAnalyzer(setting)
            ocrEngine = OCREngine.HUAWEI_ML_KIT
            Log.i(TAG, "âœ… ä½¿ç”¨åä¸ºML Kit OCRå¼•æ“")
            LogManager.info("ğŸš€ OCRå¼•æ“ï¼šåä¸ºML Kitï¼ˆè¯†åˆ«æ›´å‡†ç¡®ï¼‰")
        } catch (e: Exception) {
            // åä¸ºML Kitä¸å¯ç”¨ï¼Œä½¿ç”¨Google ML Kit
            ocrEngine = OCREngine.GOOGLE_ML_KIT
            Log.i(TAG, "âœ… ä½¿ç”¨Google ML Kit OCRå¼•æ“")
            LogManager.info("ğŸš€ OCRå¼•æ“ï¼šGoogle ML Kitï¼ˆé€šç”¨æ–¹æ¡ˆï¼‰")
        }
    }
    
    /**
     * åˆå§‹åŒ–MediaProjectionï¼ˆéœ€è¦åœ¨è·å–æƒé™åè°ƒç”¨ï¼‰
     */
    fun initMediaProjection(projection: MediaProjection) {
        this.mediaProjection = projection
        setupImageReader()
    }
    
    private fun setupImageReader() {
        imageReader = ImageReader.newInstance(
            displayMetrics.widthPixels,
            displayMetrics.heightPixels,
            PixelFormat.RGBA_8888,
            2
        )
    }
    
    /**
     * æ‰§è¡ŒOCRè¯†åˆ«
     * @param x åŒºåŸŸå·¦ä¸Šè§’Xåæ ‡
     * @param y åŒºåŸŸå·¦ä¸Šè§’Yåæ ‡
     * @param width åŒºåŸŸå®½åº¦
     * @param height åŒºåŸŸé«˜åº¦
     * @return è¯†åˆ«åˆ°çš„æ–‡å­—ï¼Œå¤±è´¥è¿”å›null
     */
    suspend fun performOCR(x: Int, y: Int, width: Int, height: Int): String? {
        return try {
            // 1. æˆªå±
            val screenshot = captureScreen() ?: run {
                Log.e(TAG, "æˆªå±å¤±è´¥")
                return null
            }
            
            // 2. è£å‰ªåŒºåŸŸ
            val croppedBitmap = cropBitmap(screenshot, x, y, width, height)
            screenshot.recycle()
            
            // 3. OCRè¯†åˆ«
            val text = recognizeText(croppedBitmap)
            croppedBitmap.recycle()
            
            Log.d(TAG, "OCRè¯†åˆ«ç»“æœ: ($x, $y, $width, $height) -> $text")
            text
        } catch (e: Exception) {
            Log.e(TAG, "OCRè¯†åˆ«å¤±è´¥", e)
            null
        }
    }
    
    /**
     * æˆªå–å±å¹•
     */
    private suspend fun captureScreen(): Bitmap? = suspendCancellableCoroutine { continuation ->
        val projection = mediaProjection
        val reader = imageReader
        
        if (projection == null || reader == null) {
            Log.e(TAG, "MediaProjectionæˆ–ImageReaderæœªåˆå§‹åŒ–")
            continuation.resume(null)
            return@suspendCancellableCoroutine
        }
        
        try {
            // åˆ›å»ºè™šæ‹Ÿæ˜¾ç¤º
            virtualDisplay = projection.createVirtualDisplay(
                VIRTUAL_DISPLAY_NAME,
                displayMetrics.widthPixels,
                displayMetrics.heightPixels,
                displayMetrics.densityDpi,
                DisplayManager.VIRTUAL_DISPLAY_FLAG_AUTO_MIRROR,
                reader.surface,
                null,
                Handler(Looper.getMainLooper())
            )
            
            // å»¶è¿Ÿä¸€ä¸‹è®©ç”»é¢ç¨³å®š
            Handler(Looper.getMainLooper()).postDelayed({
                try {
                    val image = reader.acquireLatestImage()
                    if (image != null) {
                        val bitmap = imageToBitmap(image)
                        image.close()
                        
                        virtualDisplay?.release()
                        virtualDisplay = null
                        
                        continuation.resume(bitmap)
                    } else {
                        Log.e(TAG, "è·å–å›¾åƒå¤±è´¥")
                        virtualDisplay?.release()
                        virtualDisplay = null
                        continuation.resume(null)
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "å¤„ç†å›¾åƒå¤±è´¥", e)
                    virtualDisplay?.release()
                    virtualDisplay = null
                    continuation.resumeWithException(e)
                }
            }, 100)
            
        } catch (e: Exception) {
            Log.e(TAG, "åˆ›å»ºè™šæ‹Ÿæ˜¾ç¤ºå¤±è´¥", e)
            continuation.resumeWithException(e)
        }
    }
    
    /**
     * Imageè½¬Bitmap
     */
    private fun imageToBitmap(image: Image): Bitmap {
        val planes = image.planes
        val buffer = planes[0].buffer
        val pixelStride = planes[0].pixelStride
        val rowStride = planes[0].rowStride
        val rowPadding = rowStride - pixelStride * image.width
        
        val bitmap = Bitmap.createBitmap(
            image.width + rowPadding / pixelStride,
            image.height,
            Bitmap.Config.ARGB_8888
        )
        bitmap.copyPixelsFromBuffer(buffer)
        
        return if (rowPadding == 0) {
            bitmap
        } else {
            // è£å‰ªæ‰padding
            val croppedBitmap = Bitmap.createBitmap(bitmap, 0, 0, image.width, image.height)
            bitmap.recycle()
            croppedBitmap
        }
    }
    
    /**
     * è£å‰ªBitmap
     */
    private fun cropBitmap(source: Bitmap, x: Int, y: Int, width: Int, height: Int): Bitmap {
        // ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        val safeX = x.coerceIn(0, source.width - 1)
        val safeY = y.coerceIn(0, source.height - 1)
        val safeWidth = width.coerceAtMost(source.width - safeX)
        val safeHeight = height.coerceAtMost(source.height - safeY)
        
        return Bitmap.createBitmap(source, safeX, safeY, safeWidth, safeHeight)
    }
    
    /**
     * ä½¿ç”¨å¯¹åº”å¼•æ“è¯†åˆ«æ–‡å­—
     */
    private suspend fun recognizeText(bitmap: Bitmap): String? {
        return when (ocrEngine) {
            OCREngine.HUAWEI_ML_KIT -> recognizeTextWithHuawei(bitmap)
            OCREngine.GOOGLE_ML_KIT -> recognizeTextWithGoogle(bitmap)
            OCREngine.UNKNOWN -> {
                Log.e(TAG, "OCRå¼•æ“æœªåˆå§‹åŒ–")
                null
            }
        }
    }
    
    /**
     * ä½¿ç”¨åä¸ºML Kitè¯†åˆ«æ–‡å­—
     */
    private suspend fun recognizeTextWithHuawei(bitmap: Bitmap): String? = suspendCancellableCoroutine { continuation ->
        try {
            val frame = MLFrame.fromBitmap(bitmap)
            val task = huaweiTextAnalyzer?.asyncAnalyseFrame(frame)
            
            task?.addOnSuccessListener { mlText ->
                val text = mlText?.stringValue?.trim() ?: ""
                Log.d(TAG, "[åä¸ºML Kit] è¯†åˆ«ç»“æœ: $text")
                continuation.resume(if (text.isNotEmpty()) text else null)
            }?.addOnFailureListener { e ->
                Log.e(TAG, "[åä¸ºML Kit] è¯†åˆ«å¤±è´¥", e)
                continuation.resume(null)
            } ?: continuation.resume(null)
        } catch (e: Exception) {
            Log.e(TAG, "[åä¸ºML Kit] è¯†åˆ«å¼‚å¸¸", e)
            continuation.resume(null)
        }
    }
    
    /**
     * ä½¿ç”¨Google ML Kitè¯†åˆ«æ–‡å­—
     */
    private suspend fun recognizeTextWithGoogle(bitmap: Bitmap): String? = suspendCancellableCoroutine { continuation ->
        try {
            val inputImage = InputImage.fromBitmap(bitmap, 0)
            
            googleTextRecognizer.process(inputImage)
                .addOnSuccessListener { visionText ->
                    val text = visionText.text.trim()
                    Log.d(TAG, "[Google ML Kit] è¯†åˆ«ç»“æœ: $text")
                    continuation.resume(if (text.isNotEmpty()) text else null)
                }
                .addOnFailureListener { e ->
                    Log.e(TAG, "[Google ML Kit] è¯†åˆ«å¤±è´¥", e)
                    continuation.resume(null)
                }
        } catch (e: Exception) {
            Log.e(TAG, "[Google ML Kit] è¯†åˆ«å¼‚å¸¸", e)
            continuation.resume(null)
        }
    }
    
    /**
     * è·å–å½“å‰ä½¿ç”¨çš„OCRå¼•æ“
     */
    fun getOCREngineName(): String {
        return when (ocrEngine) {
            OCREngine.HUAWEI_ML_KIT -> "åä¸ºML Kit"
            OCREngine.GOOGLE_ML_KIT -> "Google ML Kit"
            OCREngine.UNKNOWN -> "æœªçŸ¥"
        }
    }
    
    /**
     * é‡Šæ”¾èµ„æº
     */
    fun release() {
        virtualDisplay?.release()
        virtualDisplay = null
        
        imageReader?.close()
        imageReader = null
        
        mediaProjection?.stop()
        mediaProjection = null
        
        try {
            googleTextRecognizer.close()
        } catch (e: Exception) {
            Log.e(TAG, "å…³é—­Googleè¯†åˆ«å™¨å¤±è´¥", e)
        }
        
        try {
            huaweiTextAnalyzer?.stop()
            huaweiTextAnalyzer = null
        } catch (e: Exception) {
            Log.e(TAG, "å…³é—­åä¸ºè¯†åˆ«å™¨å¤±è´¥", e)
        }
    }
}
